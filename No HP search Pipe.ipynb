{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82cabb48-ec7d-4ce0-8a11-f45c05b8c9f5",
   "metadata": {},
   "source": [
    "## Altered pipeline using cross_validate and base classifiers (no hyperparemeters or search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dc9d31-4020-4ce7-b6c5-54c22211d214",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d21a12e0-921b-461a-8ac3-99d66cb7c903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "from os import path as op\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from yaml import CLoader as Loader\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "# MNE\n",
    "import mne\n",
    "from mne_bids import write_raw_bids, BIDSPath, update_sidecar_json\n",
    "from mne_bids.stats import count_events\n",
    "from mne import io, EvokedArray\n",
    "from mne.decoding import Vectorizer, get_coef, LinearModel\n",
    "# Scikit-learn\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import PrecisionRecallDisplay, ConfusionMatrixDisplay, classification_report, make_scorer, balanced_accuracy_score, fbeta_score, precision_recall_curve, precision_score, recall_score, accuracy_score, roc_auc_score, f1_score, matthews_corrcoef, confusion_matrix\n",
    "    # Classifiers\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC    \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "mne.set_log_level(verbose='Warning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0fa02dd-320e-49d0-b3fe-e13c8517cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = ['Neutral/Upright/Faces/Target','Neutral/Upright/Faces/Standard',\n",
    "              'Neutral/Upright/Silhouettes/Target','Neutral/Upright/Silhouettes/Standard',\n",
    "              \n",
    "              'Green/Upright/Faces/Target','Green/Upright/Faces/Standard',\n",
    "              'Green/Upright/Silhouettes/Target','Green/Upright/Silhouettes/Standard',\n",
    "              \n",
    "              'Neutral/Inverted/Faces/Target','Neutral/Inverted/Faces/Standard',\n",
    "              'Neutral/Inverted/Silhouettes/Target','Neutral/Inverted/Silhouettes/Standard',\n",
    "              \n",
    "              'Green/Inverted/Faces/Target','Green/Inverted/Faces/Standard',\n",
    "              'Green/Inverted/Silhouettes/Target','Green/Inverted/Silhouettes/Standard',\n",
    "              \n",
    "              'Target', 'Standard'\n",
    "             ]\n",
    "\n",
    "coi = ['Target', 'Standard']\n",
    "\n",
    "contrasts = {'Neutral/Upright/Faces':['Neutral/Upright/Faces/Target','Neutral/Upright/Faces/Standard'],\n",
    "             'Neutral/Upright/Silhouettes':['Neutral/Upright/Silhouettes/Target','Neutral/Upright/Silhouettes/Standard'],\n",
    "             \n",
    "             'Green/Upright/Faces':['Green/Upright/Faces/Target','Green/Upright/Faces/Standard'],\n",
    "             'Green/Upright/Silhouettes':['Green/Upright/Silhouettes/Target','Green/Upright/Silhouettes/Standard'],\n",
    "             \n",
    "             'Neutral/Inverted/Faces':['Neutral/Inverted/Faces/Target','Neutral/Inverted/Faces/Standard'],\n",
    "             'Neutral/Inverted/Silhouettes':['Neutral/Inverted/Silhouettes/Target','Neutral/Inverted/Silhouettes/Standard'],\n",
    "             \n",
    "             'Green/Inverted/Faces':['Green/Inverted/Faces/Target','Green/Inverted/Faces/Standard'],\n",
    "             'Green/Inverted/Silhouettes':['Green/Inverted/Silhouettes/Target','Green/Inverted/Silhouettes/Standard'],\n",
    "             \n",
    "             'Target-Nontarget':['Target', 'Standard']\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013ab46a-5a70-4f49-a635-c238688f278e",
   "metadata": {},
   "source": [
    "### Yaml + Pathing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83370f26-b562-4e57-bcde-f0fc3d86ea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## YAML\n",
    "bids_root = '../..'\n",
    "\n",
    "cfg_file = op.join(bids_root, 'config.yml')\n",
    "with open(cfg_file, 'r') as f:\n",
    "    config = yaml.load(f, Loader=Loader)\n",
    "\n",
    "study_name = config['study_name']\n",
    "task = config['task']\n",
    "data_type = config['data_type']\n",
    "eog = config['eog']\n",
    "montage_fname = config['montage_fname']\n",
    "n_jobs = 22\n",
    "\n",
    "epoch_p =  {k: v for d in config['preprocessing_settings']['epoch'] for k, v in d.items()}\n",
    "\n",
    "cl_p = {k: v for d in config['classification'] for k, v in d.items()}\n",
    "\n",
    "## Pathing\n",
    "source_path = op.join(bids_root, 'derivatives', 'erp_preprocessing')\n",
    "\n",
    "derivatives_path = op.join(bids_root, 'derivatives', 'erp_classification_test_' + str(cl_p['test_size'])[-1] + '0_pct')\n",
    "if Path(derivatives_path).exists() == False:\n",
    "    Path(derivatives_path).mkdir(parents=True)\n",
    "\n",
    "out_path = op.join(derivatives_path, 'data')\n",
    "if Path(out_path).exists() == False:\n",
    "    Path(out_path).mkdir(parents=True)\n",
    "\n",
    "report_path = op.join(derivatives_path, 'reports')\n",
    "if Path(report_path).exists() == False:\n",
    "    Path(report_path).mkdir(parents=True)\n",
    "\n",
    "fig_path = op.join(derivatives_path, 'figures')\n",
    "if Path(fig_path).exists() == False:\n",
    "    Path(fig_path).mkdir(parents=True) \n",
    "\n",
    "tab_path = op.join(derivatives_path, 'tables')\n",
    "if Path(tab_path).exists() == False:\n",
    "    Path(tab_path).mkdir(parents=True) \n",
    "    \n",
    "epochs_suffix = '-epo.fif'\n",
    "\n",
    "## Output files\n",
    "out_file = op.join(tab_path, 'classification_overall_results.csv')\n",
    "summary_file =  op.join(tab_path, 'classification_accuracy_summary.csv')\n",
    "plot_stem = op.join(fig_path, 'plot_')\n",
    "fig_format = 'pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c75a743-44bd-4e6e-b4c1-d49a4be1c61e",
   "metadata": {},
   "source": [
    "### Instantiating classifiers, parameter grids, and scoring metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94bf465a-18fd-48e7-81a3-76a02df33e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "vectorizer = Vectorizer()\n",
    "\n",
    "svm = LinearSVC(random_state=42, max_iter=5000, dual=True)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=10)\n",
    "\n",
    "\n",
    "classifiers = {'SVM': svm,\n",
    "               'LDA': lda,\n",
    "               'RF': rf\n",
    "              }\n",
    "\n",
    "## SCORING\n",
    "scoring = {'Prec': make_scorer(precision_score, zero_division=0),\n",
    "           'Bal_Acc': make_scorer(balanced_accuracy_score),\n",
    "           'Acc': make_scorer(accuracy_score),\n",
    "           'Recall': make_scorer(recall_score),\n",
    "           'ROC': make_scorer(roc_auc_score),\n",
    "           'Matthews_Coef': make_scorer(matthews_corrcoef),\n",
    "           'Fbeta_0.5': make_scorer(fbeta_score, beta = 0.5),\n",
    "           'Fbeta_1.5': make_scorer(fbeta_score, beta = 1.5),\n",
    "           'F1_score': make_scorer(f1_score, zero_division=0)\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363d2db4-d480-44f3-8c00-d6ce0b6ac728",
   "metadata": {},
   "source": [
    "### Subjects + Loading em' in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e87ec5a-d8b4-452e-8186-e3e482d634a0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## For Running All Participants' Data in Batch\n",
    "prefix = 'sub-'\n",
    "subjects = sorted([s[-7:] for s in glob(source_path + '/' + prefix + '*')])\n",
    "print(\"n subjects = \", len(subjects))\n",
    "\n",
    "\n",
    "## Reading in data\n",
    "epochs = {}\n",
    "print('Loading Subjects:', subjects)\n",
    "for subject in subjects:\n",
    "    raw_path = op.join(bids_root, 'derivatives', 'erp_preprocessing', subject, 'eeg')\n",
    "    raw_subj = glob(op.join(raw_path + '/' + '*-epo.fif'))\n",
    "    \n",
    "    \n",
    "    epochs[subject] = mne.read_epochs(raw_subj.pop(), proj=False, verbose=False, preload=True)\n",
    "\n",
    "    \n",
    "    # Correcting for presentation delay\n",
    "    epochs[subject]._raw_times = epochs[subject]._raw_times - epoch_p['tshift']\n",
    "    epochs[subject]._times_readonly = epochs[subject]._times_readonly - epoch_p['tshift']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ca3dc2-7c8f-40a7-9ff3-407823f7bfa3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochdf = pd.DataFrame()\n",
    "epochlist = []\n",
    "\n",
    "for subject in subjects:\n",
    "\n",
    "    raw_path = op.join(bids_root, 'derivatives', 'erp_preprocessing', subject, 'eeg')\n",
    "    \n",
    "    raw_subj = glob(op.join(raw_path + '/' + '*-epo.fif'))\n",
    "    \n",
    "    epochs = mne.read_epochs(raw_subj.pop(), proj=False, preload=True)\n",
    "    num_epochs = len(epochs)\n",
    "\n",
    "    print(f'Subject {subject} has: {num_epochs}')\n",
    "    \n",
    "    epochlist.append(pd.DataFrame({'subject':subject,\n",
    "                                   '# epochs':num_epochs}, index=[0]))\n",
    "    \n",
    "epochdf = pd.concat(epochlist)\n",
    "epochdf.to_csv('participant_epoch_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d239826-3a56-4b90-aaad-4bdd8bef8fd3",
   "metadata": {},
   "source": [
    "### Batch Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde30452-6b7c-4e4a-a191-fde2aecb8964",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%xmode Verbose\n",
    "\n",
    "# Making the crossvalidation to be used in the RandomizedSearch\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for subject in subjects:\n",
    "    print('\\n-------\\n\\033[;40m' + subject + '\\033[m')\n",
    "    \n",
    "    # Clearing out the saved data for each participant\n",
    "    data_table = pd.DataFrame()\n",
    "    data_table_list = []\n",
    "    \n",
    "    for contr, conds in contrasts.items():\n",
    "        print('-------\\n\\033[94;40m' + contr + '\\033[m')\n",
    "        subj_epochs = epochs[subject][conds]\n",
    "        \n",
    "        # Create a list of labels from event codes mapped to event_id\n",
    "        event_id_rev = dict(zip(subj_epochs.event_id.values(), subj_epochs.event_id.keys()))\n",
    "        labels_all = [event_id_rev[e] for e in subj_epochs.events[:, 2]]\n",
    "        labels_all = pd.DataFrame(labels_all)[0].str.split('/', expand=True).rename(columns={0:'Colour', 1:'Orientation', 2:'Type', 3:'Status', 4:'Location'} )\n",
    "        label_map = {'Target':1, 'Standard':0}\n",
    "        labels_all['labels'] = labels_all['Status'].map(label_map)\n",
    "        labels = labels_all['labels']\n",
    "        \n",
    "        # Extract data from subj_epochs and vectorize \n",
    "        D = subj_epochs.get_data()\n",
    "        \n",
    "        # Create train-test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(D, \n",
    "                                                            labels,\n",
    "                                                            stratify=labels,\n",
    "                                                            test_size=cl_p['test_size'], \n",
    "                                                            random_state=42,\n",
    "                                                            shuffle=True\n",
    "                                                           )\n",
    "\n",
    "        # Classifier Loop\n",
    "        for c_name, c in classifiers.items():\n",
    "            print('-------\\nRunning classifier: \\033[1;91;40m' + c_name + '\\033[m')\n",
    "\n",
    "            # Making the Pipeline\n",
    "            clf = Pipeline([('Vectorizer', vectorizer),\n",
    "                             ('Scaler', scaler),\n",
    "                             (c_name, c)                                 \n",
    "                             ])\n",
    "\n",
    "            # Cross validating\n",
    "            cv_cv = cross_validate(clf, X_train, y_train, \n",
    "                                   cv=cv,\n",
    "                                   scoring=scoring,\n",
    "                                   return_train_score=True, # Determines if Training scores are included in .cv_results_\n",
    "                                   n_jobs=5,\n",
    "                                   error_score='raise' # For debugging purposes\n",
    "                                   )\n",
    "\n",
    "            print('Training Classifier')\n",
    "            clf = clf.fit(X_train, y_train)\n",
    "\n",
    "            print('Predicting...')\n",
    "            y_pred = clf.predict(X_test)\n",
    "\n",
    "            print('Scoring...')        \n",
    "            print(classification_report(y_test, y_pred))\n",
    "\n",
    "            # Confusion Matrix Generation and Visualization within the loop -> saved to csv as \"[[TN, FN] [FP, TP]]\"\n",
    "            cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\n",
    "            cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "            cmd.plot()\n",
    "            plt.title(subject + '_' + str(contr).replace('/', '_') + '_' + c_name)\n",
    "            plt.show()\n",
    "\n",
    "            # Saving CV results to a DataFrame \n",
    "            results = pd.DataFrame(cv_cv)\n",
    "\n",
    "            data_table_list.append(pd.DataFrame({'participant_id': subject,\n",
    "                                              'Condition': contr,\n",
    "                                              'Classifier': c_name,\n",
    "\n",
    "                                              # Confusion_matrix saved in format: [[TN, FN] [FP, TP]]\n",
    "                                              'Confusion_Matrix': str(cm),                                                 \n",
    "\n",
    "                                              'CV_Train_Bal_Accuracy': results['train_Bal_Acc'].round(3) * 100,\n",
    "                                              'CV_Test_Bal_Accuracy': results['test_Bal_Acc'].round(3) * 100,\n",
    "                                              'Test_Bal_Accuracy': round(balanced_accuracy_score(y_test, y_pred), 3) * 100,\n",
    "\n",
    "                                              'CV_Train_Accuracy': results['train_Acc'].round(3) * 100,\n",
    "                                              'CV_Test_Accuracy': results['test_Acc'].round(3) * 100,\n",
    "                                              'Test_Accuracy': round(accuracy_score(y_test, y_pred), 3) * 100, \n",
    "\n",
    "                                              'CV_Train_Precision': results['train_Prec'].round(3) * 100,\n",
    "                                              'CV_Test_Precision': results['test_Prec'].round(3) * 100,                                                \n",
    "                                              'Test_Precision': round(precision_score(y_test, y_pred, zero_division=0), 3) * 100,    \n",
    "\n",
    "                                              'CV_Train_Matthews_coef': results['train_Matthews_Coef'].round(3),\n",
    "                                              'CV_Test_Matthews_coef': results['test_Matthews_Coef'].round(3),\n",
    "                                              'Matthews_Coef': round(matthews_corrcoef(y_test, y_pred), 3),\n",
    "\n",
    "                                              'CV_Train_Recall': results['train_Recall'].round(3) * 100,\n",
    "                                              'CV_Test_Recall': results['test_Recall'].round(3) * 100,\n",
    "                                              'Test_recall': round(recall_score(y_test, y_pred), 3) * 100,\n",
    "\n",
    "                                              'CV_Train_Fbeta_0.5': results['train_Fbeta_0.5'].round(3),\n",
    "                                              'CV_Train_Fbeta_0.5': results['train_Fbeta_0.5'].round(3),\n",
    "                                              'Fbeta_0.5': round(fbeta_score(y_test, y_pred, beta = 0.5, zero_division=0), 3),\n",
    "\n",
    "                                              'CV_Train_Fbeta_1.5': results['train_Fbeta_1.5'].round(3),\n",
    "                                              'CV_Test_Fbeta_1.5': results['test_Fbeta_1.5'].round(3),\n",
    "                                              'Fbeta_1.5': round(fbeta_score(y_test, y_pred, beta = 1.5, zero_division=0), 3),\n",
    "\n",
    "                                              'CV_Train_F1': results['train_F1_score'].round(3),\n",
    "                                              'CV_Test_F1': results['test_F1_score'].round(3),\n",
    "                                              'F1_score': round(f1_score(y_test, y_pred, zero_division=0), 3),\n",
    "\n",
    "                                              'CV_Train_ROC_AUC': results['train_ROC'].round(3),\n",
    "                                              'CV_Test_ROC_AUC': results['test_ROC'].round(3),                                             \n",
    "                                              'Test_ROC_AUC': round(roc_auc_score(y_test, y_pred), 3),\n",
    "\n",
    "                                              'Mean Fit Time': results['fit_time'].round(3),\n",
    "                                              'Mean Score Time': results['score_time'].round(3)\n",
    "                                             }, index=[0]\n",
    "                                            )\n",
    "                               )\n",
    "\n",
    "    # Saving Data to CSV Per Participant\n",
    "    data_table = pd.concat(data_table_list)\n",
    "    data_table.to_csv(f'[Directory] {str(subject)} new_Data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
