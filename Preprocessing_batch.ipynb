{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c88bcae9-2be4-42d0-965f-c37d3a0f1523",
   "metadata": {},
   "source": [
    "# EEG-ERP Preprocessing â€“ Batch script\n",
    "## Max Independent Research Project; Under Brynn and Danny\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac39eca-966d-4082-8191-7ddf244016d2",
   "metadata": {},
   "source": [
    "## Subject list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834a020f-80e5-4cea-a179-a8675d7ff6af",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39db9a01-dd5f-4cc7-8607-2fc0be02abb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as op\n",
    "from os import remove\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from yaml import CLoader as Loader\n",
    "import mne\n",
    "mne.set_log_level('error')\n",
    "from mne_bids import BIDSPath, read_raw_bids\n",
    "from scipy.stats import zscore\n",
    "from autoreject import Ransac, get_rejection_threshold, AutoReject\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056b8946-693c-4056-97e0-51a3e4cf37ce",
   "metadata": {},
   "source": [
    "## Read Parameters from config.yml\n",
    "\n",
    "Will import study-level parameters from `config.yml` in `bids_root`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04cd9b59-c923-4fe1-8dc7-dbf11fcee525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this shouldn't change if you run this script from its default location in code/import\n",
    "bids_root = '../..'\n",
    "\n",
    "cfg_file = op.join(bids_root, 'config.yml')\n",
    "with open(cfg_file, 'r') as f:\n",
    "    config = yaml.load(f, Loader=Loader)\n",
    "\n",
    "study_name = config['study_name']\n",
    "task = config['task']\n",
    "data_type = config['data_type']\n",
    "eog = config['eog']\n",
    "montage_fname = config['montage_fname']\n",
    "\n",
    "# fix per changes to config\n",
    "filt_p = {k: v for d in config['preprocessing_settings']['filter'] for k, v in d.items()}\n",
    "n_jobs = filt_p['n_jobs']\n",
    "ica_p =  {k: v for d in config['preprocessing_settings']['ica'] for k, v in d.items()}\n",
    "epoch_p =  {k: v for d in config['preprocessing_settings']['epoch'] for k, v in d.items()}\n",
    "baseline = tuple(epoch_p['baseline'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa200a5-a96f-47de-9ec5-f9f797d17116",
   "metadata": {},
   "source": [
    "## Event codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6aef171-96d0-40f2-9bf4-93396d0feeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_id = {'Neutral/Upright/Faces/Standard/L1':111, #Faces\n",
    "            'Neutral/Upright/Faces/Standard/L2':112,\n",
    "            'Neutral/Upright/Faces/Standard/L3':113,\n",
    "            'Neutral/Upright/Faces/Standard/L4':114,\n",
    "            'Neutral/Upright/Faces/Standard/L5':115,\n",
    "            'Neutral/Upright/Faces/Standard/L6':116,\n",
    "\n",
    "            'Neutral/Inverted/Faces/Standard/L1':121,\n",
    "            'Neutral/Inverted/Faces/Standard/L2':122,\n",
    "            'Neutral/Inverted/Faces/Standard/L3':123,\n",
    "            'Neutral/Inverted/Faces/Standard/L4':124,\n",
    "            'Neutral/Inverted/Faces/Standard/L5':125,\n",
    "            'Neutral/Inverted/Faces/Standard/L6':126,\n",
    "\n",
    "            'Green/Upright/Faces/Standard/L1':211,\n",
    "            'Green/Upright/Faces/Standard/L2':212,\n",
    "            'Green/Upright/Faces/Standard/L3':213,\n",
    "            'Green/Upright/Faces/Standard/L4':214,\n",
    "            'Green/Upright/Faces/Standard/L5':215,\n",
    "            'Green/Upright/Faces/Standard/L6':216,\n",
    "\n",
    "            'Green/Inverted/Faces/Standard/L1':221,\n",
    "            'Green/Inverted/Faces/Standard/L2':222,\n",
    "            'Green/Inverted/Faces/Standard/L3':223,\n",
    "            'Green/Inverted/Faces/Standard/L4':224,\n",
    "            'Green/Inverted/Faces/Standard/L5':225,\n",
    "            'Green/Inverted/Faces/Standard/L6':226,\n",
    "            \n",
    "            'Neutral/Upright/Silhouettes/Standard/L1':131, #Silhouettes\n",
    "            'Neutral/Upright/Silhouettes/Standard/L2':132,\n",
    "            'Neutral/Upright/Silhouettes/Standard/L3':133,\n",
    "            'Neutral/Upright/Silhouettes/Standard/L4':134,\n",
    "            'Neutral/Upright/Silhouettes/Standard/L5':135,\n",
    "            'Neutral/Upright/Silhouettes/Standard/L6':136,\n",
    "\n",
    "            'Neutral/Inverted/Silhouettes/Standard/L1':141,\n",
    "            'Neutral/Inverted/Silhouettes/Standard/L2':142,\n",
    "            'Neutral/Inverted/Silhouettes/Standard/L3':143,\n",
    "            'Neutral/Inverted/Silhouettes/Standard/L4':144,\n",
    "            'Neutral/Inverted/Silhouettes/Standard/L5':145,\n",
    "            'Neutral/Inverted/Silhouettes/Standard/L6':146,\n",
    "\n",
    "            'Green/Upright/Silhouettes/Standard/L1':231,\n",
    "            'Green/Upright/Silhouettes/Standard/L2':232,\n",
    "            'Green/Upright/Silhouettes/Standard/L3':233,\n",
    "            'Green/Upright/Silhouettes/Standard/L4':234,\n",
    "            'Green/Upright/Silhouettes/Standard/L5':235,\n",
    "            'Green/Upright/Silhouettes/Standard/L6':236,\n",
    "\n",
    "            'Green/Inverted/Silhouettes/Standard/L1':241,\n",
    "            'Green/Inverted/Silhouettes/Standard/L2':242,\n",
    "            'Green/Inverted/Silhouettes/Standard/L3':243,\n",
    "            'Green/Inverted/Silhouettes/Standard/L4':244,\n",
    "            'Green/Inverted/Silhouettes/Standard/L5':245,\n",
    "            'Green/Inverted/Silhouettes/Standard/L6':246\n",
    "           }\n",
    "\n",
    "target_highlight_id = {'Cue/L1':191,\n",
    "                      'Cue/L2':192,\n",
    "                      'Cue/L3':193,\n",
    "                      'Cue/L4':194,\n",
    "                      'Cue/L5':195,\n",
    "                      'Cue/L6':196,\n",
    "                     }\n",
    "\n",
    "target_id = {'Neutral/Upright/Faces/Target/L1':1111, #Faces\n",
    "            'Neutral/Upright/Faces/Target/L2':1112,\n",
    "            'Neutral/Upright/Faces/Target/L3':1113,\n",
    "            'Neutral/Upright/Faces/Target/L4':1114,\n",
    "            'Neutral/Upright/Faces/Target/L5':1115,\n",
    "            'Neutral/Upright/Faces/Target/L6':1116,\n",
    "\n",
    "            'Neutral/Inverted/Faces/Target/L1':1121,\n",
    "            'Neutral/Inverted/Faces/Target/L2':1122,\n",
    "            'Neutral/Inverted/Faces/Target/L3':1123,\n",
    "            'Neutral/Inverted/Faces/Target/L4':1124,\n",
    "            'Neutral/Inverted/Faces/Target/L5':1125,\n",
    "            'Neutral/Inverted/Faces/Target/L6':1126,\n",
    "\n",
    "            'Green/Upright/Faces/Target/L1':1211,\n",
    "            'Green/Upright/Faces/Target/L2':1212,\n",
    "            'Green/Upright/Faces/Target/L3':1213,\n",
    "            'Green/Upright/Faces/Target/L4':1214,\n",
    "            'Green/Upright/Faces/Target/L5':1215,\n",
    "            'Green/Upright/Faces/Target/L6':1216,\n",
    "\n",
    "            'Green/Inverted/Faces/Target/L1':1221,\n",
    "            'Green/Inverted/Faces/Target/L2':1222,\n",
    "            'Green/Inverted/Faces/Target/L3':1223,\n",
    "            'Green/Inverted/Faces/Target/L4':1224,\n",
    "            'Green/Inverted/Faces/Target/L5':1225,\n",
    "            'Green/Inverted/Faces/Target/L6':1226,\n",
    "            \n",
    "            'Neutral/Upright/Silhouettes/Target/L1':1131, #Silhouettes \n",
    "            'Neutral/Upright/Silhouettes/Target/L2':1132,\n",
    "            'Neutral/Upright/Silhouettes/Target/L3':1133,\n",
    "            'Neutral/Upright/Silhouettes/Target/L4':1134,\n",
    "            'Neutral/Upright/Silhouettes/Target/L5':1135,\n",
    "            'Neutral/Upright/Silhouettes/Target/L6':1136,\n",
    "\n",
    "            'Neutral/Inverted/Silhouettes/Target/L1':1141,\n",
    "            'Neutral/Inverted/Silhouettes/Target/L2':1142,\n",
    "            'Neutral/Inverted/Silhouettes/Target/L3':1143,\n",
    "            'Neutral/Inverted/Silhouettes/Target/L4':1144,\n",
    "            'Neutral/Inverted/Silhouettes/Target/L5':1145,\n",
    "            'Neutral/Inverted/Silhouettes/Target/L6':1146,\n",
    "\n",
    "            'Green/Upright/Silhouettes/Target/L1':1231,\n",
    "            'Green/Upright/Silhouettes/Target/L2':1232,\n",
    "            'Green/Upright/Silhouettes/Target/L3':1233,\n",
    "            'Green/Upright/Silhouettes/Target/L4':1234,\n",
    "            'Green/Upright/Silhouettes/Target/L5':1235,\n",
    "            'Green/Upright/Silhouettes/Target/L6':1236,\n",
    "\n",
    "            'Green/Inverted/Silhouettes/Target/L1':1241,\n",
    "            'Green/Inverted/Silhouettes/Target/L2':1242,\n",
    "            'Green/Inverted/Silhouettes/Target/L3':1243,\n",
    "            'Green/Inverted/Silhouettes/Target/L4':1244,\n",
    "            'Green/Inverted/Silhouettes/Target/L5':1245,\n",
    "            'Green/Inverted/Silhouettes/Target/L6':1246\n",
    "           }\n",
    "\n",
    "event_id = {**target_highlight_id, **trial_id, **target_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0011eb68-416b-403b-827a-14f9ff378b78",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98c1f3fd-0f0b-4989-95e3-1f1aeea231d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = op.join(bids_root, 'rawdata')\n",
    "\n",
    "derivatives_path = op.join(bids_root, 'derivatives', 'erp_preprocessing')\n",
    "if Path(derivatives_path).exists() == False:\n",
    "    Path(derivatives_path).mkdir(parents=True)\n",
    "\n",
    "report_path = op.join(derivatives_path, 'logs')\n",
    "if Path(report_path).exists() == False:\n",
    "    Path(report_path).mkdir(parents=True)\n",
    "\n",
    "epochs_suffix = '-epo.fif'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca24dede",
   "metadata": {},
   "source": [
    "## Load list of ICs to manually add/remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fe1c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_file = './participants_manual_ic.yml'\n",
    "with open(cfg_file, 'r') as f:\n",
    "    ica_manual = yaml.load(f, Loader=Loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073450e3-1fa8-4aea-bbfb-034fae90b3d9",
   "metadata": {},
   "source": [
    "### Subjects, Useful variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae2e3cdd-5230-470a-9526-78e40c83078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full-Batch Preprocessing\n",
    "prefix = 'sub-'\n",
    "subjects = sorted([s[-7:] for s in glob(raw_path + '/' + prefix + '*')])\n",
    "print(\"n subjects = \", len(subjects))\n",
    "\n",
    "\n",
    "px = 1 / plt.rcParams['figure.dpi']  # pixel in inches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696f9344-3bcc-49eb-b322-c22bdecb0fce",
   "metadata": {},
   "source": [
    "## Do Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d415c9-834f-40cc-8cd4-bf6e16052045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    start_time = time()\n",
    "    print('\\n-------------------------')\n",
    "    print('-------- ' + subject + ' --------')\n",
    "    print('-------------------------')\n",
    "    \n",
    "    ### Read data\n",
    "    report = mne.Report(subject=subject, \n",
    "                        title=study_name + ' preprocessing: ' + subject,\n",
    "                        verbose='WARNING')\n",
    "\n",
    "    ### subject-specific paths\n",
    "    in_path = BIDSPath(root=raw_path, \n",
    "                        subject=subject[-3:], \n",
    "                        datatype=data_type,\n",
    "                        task=task\n",
    "                        )    \n",
    "\n",
    "    ### Import data\n",
    "    raw = read_raw_bids(in_path)\n",
    "\n",
    "    ### Filtering\n",
    "\n",
    "    # channel selection\n",
    "    picks = mne.pick_types(raw.info, \n",
    "                           eeg=True,\n",
    "                           eog=True\n",
    "                          )\n",
    "\n",
    "    ## Filter for ICA  \n",
    "    raw_ica = raw.load_data().copy().filter(filt_p['l_freq_ica'], filt_p['h_freq'],\n",
    "                                picks=picks,\n",
    "                                n_jobs=n_jobs\n",
    "                               )\n",
    "\n",
    "    ## Filter for final\n",
    "    raw.filter(filt_p['l_freq'], filt_p['h_freq'],\n",
    "               picks=picks,\n",
    "               n_jobs=n_jobs\n",
    "              )\n",
    "\n",
    "    ## Add raw to report\n",
    "    report.add_raw(raw=raw, \n",
    "               psd=True, butterfly=True, \n",
    "               title='Raw data, bandpass filtered ' + str(filt_p['l_freq']) + 'â€“' + str(filt_p['h_freq'])\n",
    "              )\n",
    "\n",
    "    ### Read events\n",
    "\n",
    "    events, event_dict = mne.events_from_annotations(raw)\n",
    "\n",
    "    ### Event Code Processing\n",
    "    #### Find indices of codes of various types\n",
    "\n",
    "    target_codes = sorted(target_highlight_id.values())\n",
    "    target_highlights = np.squeeze(np.where((events[:, 2] >= target_codes[0])  \n",
    "                                            & (events[:, 2] <= target_codes[-1])\n",
    "                                           )\n",
    "                                  )\n",
    "\n",
    "    # add these first; events don't actually need to be listed in chronological order\n",
    "    events_new = np.copy(events[target_highlights])\n",
    "\n",
    "    for block, start_idx in enumerate(target_highlights):\n",
    "        # find end of block from next target highlight, except for last block\n",
    "        if block == len(target_highlights) - 1:\n",
    "            block_trials = np.copy(events[start_idx + 1:])\n",
    "        else:\n",
    "            block_trials = np.copy(events[start_idx + 1:target_highlights[block + 1]])\n",
    "\n",
    "        # isloate value in the the ones column, which specifies position of target\n",
    "        target_code = events[start_idx, 2] % 10\n",
    "\n",
    "        # create filter/mask\n",
    "        targets = block_trials[:, 2] % 10 == target_code\n",
    "\n",
    "        block_trials[targets, 2] = block_trials[targets, 2] + 1000\n",
    "\n",
    "        events_new = np.vstack((events_new, block_trials))\n",
    "        \n",
    "    ### Create dictionary of event labels for only those event codes actually present in the data\n",
    "    event_dict_new = {}\n",
    "    codes_in_data = np.unique(events_new[:, 2])    \n",
    "\n",
    "    for key, value in event_id.items():\n",
    "        if value in codes_in_data:\n",
    "            event_dict_new[key] = value\n",
    "\n",
    "    ## Add events to report\n",
    "    report.add_events(events_new, event_id=event_dict_new, \n",
    "                      sfreq=raw.info['sfreq'],\n",
    "                      title='Events'\n",
    "                     )\n",
    "    \n",
    "\n",
    "    #################################\n",
    "    ### Epoch data filtered for ICA\n",
    "\n",
    "    epochs_ica = mne.Epochs(raw_ica,\n",
    "                            events_new, event_dict_new,\n",
    "                            epoch_p['tmin'], epoch_p['tmax'],\n",
    "                            baseline=None, detrend=epoch_p['detrend'],\n",
    "                            reject=epoch_p['reject'], \n",
    "                            flat=epoch_p['flat'],\n",
    "                            preload=True\n",
    "                           )\n",
    "\n",
    "    ### use AutoReject to remove bad epochs, repair sensors and return clean epochs.\n",
    "\n",
    "    ar = AutoReject(n_interpolate=[1, 2, 4, 8],\n",
    "                    consensus=np.array([.5, 1., 11.]),\n",
    "                    random_state=ica_p['ica_random_state'],\n",
    "                    picks=mne.pick_types(epochs_ica.info, eeg=True, eog=False),\n",
    "                    n_jobs=n_jobs, \n",
    "                    verbose=False\n",
    "                   )\n",
    "\n",
    "    ar.fit(epochs_ica)\n",
    "\n",
    "    reject_log = ar.get_reject_log(epochs_ica)\n",
    "    fig = reject_log.plot('horizontal')\n",
    "    report.add_figure(fig=fig, title='AutoReject log, pre-ICA')\n",
    "\n",
    "    ### Fit ICA\n",
    "\n",
    "    ica = mne.preprocessing.ICA(method='fastica',\n",
    "                                n_components=ica_p['n_components'],\n",
    "                                random_state=ica_p['ica_random_state'],\n",
    "                                max_iter='auto')\n",
    "\n",
    "    ica.fit(epochs_ica[~reject_log.bad_epochs],  # added [~reject_log.bad_epochs] for AutoReject\n",
    "            decim=3, \n",
    "            # reject=reject,  # removed this line as I think it's redundant\n",
    "            picks=['eeg']\n",
    "            );\n",
    "\n",
    "    ### Identify ocular ICs\n",
    "\n",
    "    # The default *z* threshold doesn't work for\n",
    "    # all subjects. This routine starts with the default z (from config) and steps down\n",
    "    # until at least n_min_eog EOG components are identified.\n",
    "    # The limitations of this are that it assumes there will always be at least n_min_eog EOG\n",
    "    # components (blinks are always present, but horizontal movements are not\n",
    "    # always present), and may not work if there are > 3 components, if the\n",
    "    # score of the third is > `z_step` less than the score of the second.\n",
    "    # In practice, many of these components (with EGI data) may not be ocular, but are (hopefully) not EEG.\n",
    "    # Be sure to check the reports and confirm no ERP components are rejected!\n",
    "\n",
    "    ica.exclude = []\n",
    "    num_excl = 0\n",
    "    z_thresh = ica_p['ica_zthresh'] \n",
    "    z_step = ica_p['ica_zstep']\n",
    "\n",
    "    while num_excl < ica_p['n_min_eog']:\n",
    "        eog_indices, eog_scores = ica.find_bads_eog(epochs_ica, threshold=z_thresh)\n",
    "        num_excl = len(eog_indices)\n",
    "        z_thresh -= z_step # won't impact things if num_excl is â‰¥Â n_min_eog \n",
    "\n",
    "    ica.exclude = eog_indices\n",
    "    z_thresh_final = round(z_thresh + z_step, 2)\n",
    "\n",
    "    # Manual removal/re-addition of ICs based on visual inspection\n",
    "    if subject in ica_manual:\n",
    "        if 'add_ics' in ica_manual[subject]:\n",
    "            for ic in ica_manual[subject]['add_ics']:\n",
    "                ica.exclude.append(ic)\n",
    "        if 'rm_ics' in ica_manual[subject]:\n",
    "            for ic in ica_manual[subject]['rm_ics']:\n",
    "                ica.exclude.remove(ic)         \n",
    "\n",
    "    # Create average of EOG events\n",
    "    eog_evoked = mne.preprocessing.create_eog_epochs(raw_ica).average().apply_baseline(baseline=(None, epoch_p['tmin']))\n",
    "\n",
    "    ## Add ICA to report\n",
    "    report.add_ica(ica=ica, title='ICA', inst=epochs_ica,\n",
    "                   eog_evoked=eog_evoked, \n",
    "                   eog_scores=eog_scores,\n",
    "                   n_jobs=n_jobs\n",
    "                  )\n",
    "\n",
    "    ### Epoch filtered raw data into epochs for final analysis\n",
    "\n",
    "    epochs = mne.Epochs(raw,\n",
    "                        events_new, event_dict_new,\n",
    "                        epoch_p['tmin'], epoch_p['tmax'],\n",
    "                        baseline=None, detrend=epoch_p['detrend'],\n",
    "                        reject=epoch_p['reject'], \n",
    "                        flat=epoch_p['flat'],\n",
    "                        preload=True\n",
    "                       )\n",
    "\n",
    "    ### Apply ICA correction to epochs\n",
    "\n",
    "    ica.apply(epochs)\n",
    "\n",
    "    ### Apply AutoReject to further clean epochs\n",
    "\n",
    "    ar = AutoReject(n_interpolate=[1, 2, 4, 8],\n",
    "                    consensus=np.array([.5, 1., 11.]),\n",
    "                    random_state=ica_p['ica_random_state'],\n",
    "                    picks=mne.pick_types(epochs_ica.info, eeg=True, eog=False),\n",
    "                    n_jobs=n_jobs, \n",
    "                    verbose=False\n",
    "                   )\n",
    "    epochs_clean, reject_log = ar.fit_transform(epochs, return_log=True)\n",
    "    ### Plot autoreject log\n",
    "    fig = reject_log.plot('horizontal')\n",
    "    report.add_figure(fig=fig, title='AutoReject log, post-ICA')\n",
    "\n",
    "\n",
    "    ### Re-reference, now that channels are cleaned\n",
    "    #### Also, apply time shift to compensate for delay between code and onset of visual stim (based on empirical timing test)\n",
    "\n",
    "    epochs_clean.set_eeg_reference(ref_channels=epoch_p['rereference']).shift_time(epoch_p['tshift'], relative=True);\n",
    "\n",
    "    # add epochs to report\n",
    "    report.add_epochs(epochs_clean,  \n",
    "                      title='Epochs'\n",
    "                     )\n",
    "\n",
    "    ### Save cleaned epochs\n",
    "\n",
    "    out_path = BIDSPath(root=derivatives_path, \n",
    "                       subject=subject[-3:], \n",
    "                       datatype=data_type,\n",
    "                       task=task\n",
    "                      )    \n",
    "    # remove old fif file if it exists, and update bids_path\n",
    "    if str(out_path.fpath)[-len(epochs_suffix):] == epochs_suffix:\n",
    "        remove(out_path.fpath)\n",
    "        out_path = BIDSPath(root=derivatives_path, \n",
    "                   subject=subject[-3:], \n",
    "                   datatype=data_type,\n",
    "                   task=task\n",
    "                  )    \n",
    "    # save the file\n",
    "    epochs_clean.save(str(out_path.fpath) + epochs_suffix, \n",
    "                      overwrite=True)\n",
    "\n",
    "    ### Save plot of average across all trials\n",
    "\n",
    "    fig = epochs_clean.copy().average().apply_baseline(baseline).plot(spatial_colors=True, show=False);\n",
    "\n",
    "    # add figure to report\n",
    "    \n",
    "    report.add_figure(fig=fig, title='Grand average over all epochs')\n",
    "    plt.close(fig)\n",
    "\n",
    "    ### Add plots of average of each condition\n",
    "\n",
    "    coi = ['Neutral/Upright/Faces/Target',\n",
    "           'Neutral/Inverted/Faces/Target',\n",
    "           'Green/Upright/Faces/Target',\n",
    "           'Green/Inverted/Faces/Target',\n",
    "           'Neutral/Upright/Silhouettes/Target',\n",
    "           'Neutral/Inverted/Silhouettes/Target',\n",
    "           'Green/Upright/Silhouettes/Target',\n",
    "           'Green/Inverted/Silhouettes/Target',\n",
    "          ]\n",
    "\n",
    "    ylim = 15\n",
    "    for condition in coi:\n",
    "        fig = epochs_clean[condition].copy().average().plot_joint(title=('_').join(condition.split('/')),\n",
    "                                                                    ts_args={'ylim':{'eeg':[-ylim,  ylim]}},\n",
    "                                                                    show=True)\n",
    "        report.add_figure(fig=fig, title=condition)\n",
    "        plt.close(fig)\n",
    "\n",
    "    ### Save report to file\n",
    "    report_name = report_path + '/' + subject + '.html'\n",
    "    report.save(report_name, overwrite=True)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "760055932674735d287fd612619c18ffc3840c7c49c197eeb438d57975a1e213"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
